# AI
General information about AI

Over the past decade, three major drivers of improvement in AI performance have been: 

* Computational scaling: Does running an algorithm on computers 10 or 100 times faster result in better performance?
* Data scaling: Does feeding an AI system more data improve its performance?
* Algorithmic improvements: Does the data available still hold a significant amount of information that current algorithms do not  extract?

> This reasoning leads me to believe that GPT-3 is setting a new direction for building language models and applications. I see a clear path toward scaling computation (by making models cheaper to run or building bigger ones) and algorithmic improvements. At AI Fund (where I’m managing general partner), we’re seeing many entrepreneurs looking to build new companies using GPT-3. 

> When you hear about an exciting category of emerging AI technology, you might ask yourself whether it can ride on the backs of computational scaling, data scaling, and algorithmic improvement. If so, it’s more likely to make a big impact in the future. 

Source: https://blog.deeplearning.ai/blog/the-batch-youtube-vs.-conspiracy-theorists-robots-that-think-ahead-gpu-cpu-the-future-transformers-retooled
